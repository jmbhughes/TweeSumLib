@ARTICLE{vsbn07,
author = {Lucy Vanderwende and Hisami Suzuki and Chris Brockett and Ani Nenkova},
title = {Beyond sumbasic: Task-focused summarization with sentence simplification and lexical expansion},
journal = {Information Processing and Management},
volume = {43},
number = {6},
pgs = {1606-1618},
annote = {TO READ}
}

Ani Nenkova and Lucy Vanderwende. 2005. The im- pact of frequency on summarization. Microsoft Re- search, Redmond, Washington, Tech. Rep. MSR-TR- 2005-101.
@InProceedings{nv05,
author = {Aniv Nenkova and Lucy Venderwende},
year = {2005},
title = {The impact of frequency on summarization},
booktitle = {Microsoft Research, Redmond, Washington Tech. Rep. MSR-TR 2005-101}
annote = {The introductin of SumBasic}
}

@InProceedings{xgmr13,
author ={Wei Xu and Ralph Grishman and Adam Meyers and Alan Ritter},
title = {A Preliminary Study of Tweet Summarization using Information Extraction},
booktitle = {Proceedings of the Workshop on Language in Social Media (LASM 2013)},
pages = {20-29},
year = {2013},
month = {June},
day = {13},
annote = {Authors claim that their system produces summaries that are more concise and news-worthy than SumBasic as evaluated by human judges. Their graph-based appraoch uses entities, event phrases, and connections between tweets. This builds off a previous work by \cite{lxywl06} on news articles. They provide a wonderful table, Table 1, of previous works I can use as reference. They begin by identifying events in tweets. They emphasize it is important to exploit the redundancy in tweets to find meaning. They map named entities and events together in a weighted graph; edge weight is the number of tweets the nodes co-occur in. They then use a modified version of PageRank. They use human evaluation.}
}

%%

@InProceedings{lxywl06,
author = {Wenjie Li and Wei Xu and Chunfa Yuan and Mingli Wu and Qin Lu},
year = {2006},
title = {Extractive summarization using inter- and intra- event relevance},
booktitle = {Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL44},
pages = {369â€“376},
annote = {TO DOWNLOAD AND TO READ}
}

%%

@InProceedings{ca13,
author = {Freedy Chong Tat Chua and Sitaram Asur},
year = {2013},
title = {Automatic Summarization of Events from Social Media},
booktitle = {Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media},
annote = {A very sophisticated approach to identify topics using a graph model with a decay rate. Specific to twitter as well. Unfortunately, they do not provide any summary examples! }
}

%%

@InProceedings{skp13,
author = {Sandeep Sripada and Venu Gopal Kasturi and Gautam Kumar Parai},
year = {2013},
title = {Multi-document extraction based Summarization},
booktitle = {CS 224N Final Project Report},
annote = {They employ three different approaches to create summaries. Their paper is a nice overview and includes many features to consider. They discuss "stack decoder" formulations, clustering forumlations, and graph based formulations. }
}

%%

@ARTICLE{yhs15,
author = {Evi Yulianti and Sharin Huspi and Mrk Sanderson},
title = {Tweet-Biased Summarization}, 
journal = {Journal of the Association for Information Science and Technology},
pages = {1289-1300},
volume = {67},
number = {6},
year = {2015},
annote = {Describes how one must modify summarization to account for tweets. What makes  a good summary. }
}

%%

@ARTICLE{anonbasis,
author = {Anonymous ACL Submission},
title = {Argument Mining in Twitter: Recognizing Premise Tweets for Claim Hashtags},
journal = {In prep},
annote = {Hashtags can be used to identify premises. They use different features (e.g. discourse indicators, informativeness, sentiment, tone) to identify whether tweets are premise tweets or not. These are then summarized. I could provide a better summarization perchance.}
}